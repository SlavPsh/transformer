# Configuration toml
[experiment]
name = "Transformer with attention distance"
description = "Training a model with attention distance mask"

[data]
data_dir = "/data/atlas/users/spshenov/ml_input_data"
# trackml_tiny_10to50tracks_100events.csv
# trackml_short_10to50_tracks_5k_events.csv
# trackml_10to50tracks_40kevents.csv
# trackml_200to500tracks_40kevents.csv
data_file = "trackml_200to500tracks_40kevents.csv"
dataloader_num_workers = 4

[model]
num_encoder_layers = 6
d_model = 32
n_head = 4
input_size = 3
output_size = 4
dim_feedforward = 128
dropout = 0.1
use_flash_attention = false
use_att_mask = false

[training]
batch_size = 64
total_epochs = 500
shuffle = false # whether training data should be shuffled
start_from_scratch = true
default_lr = 1e-3

[training.early_stopping]
patience = 50

[output]
base_path = "/data/atlas/users/spshenov/trained_models"

[logging]
level = "INFO"
epoch_log_interval = 10
model_save_interval = 30

[wandb]
watch_interval = 50

[sweep]
entity = "spshenov-university-of-amsterdam"
project = "transformer_for_particle_tracking"
method = "grid"

[sweep.metric]
name = "train/validation loss"
goal = "minimize"

[sweep.parameters.use_att_mask]
values = [true, false]